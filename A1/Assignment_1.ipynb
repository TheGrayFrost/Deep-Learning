{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Assignment 1: Linear Regression using Numpy (No deep learning/ automatic differentiation libraries are allowed)\n",
    "\n",
    "\n",
    "Use Python2.7 environment\n",
    "Roll No:\n",
    "Name:\n",
    "\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Fix seed for reproducibility\n",
    "np.random.seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRKSkFABEREpKAUBEpKT+P2T4GBMiBVxGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109aafc10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def generate_dataset():\n",
    "    '''\n",
    "    Function to generate the dataset for our problem\n",
    "    Args:\n",
    "        None\n",
    "    Return:\n",
    "        X: \n",
    "    '''\n",
    "    N = 600\n",
    "    X = np.random.randint(100, size=N)\n",
    "    e = np.random.normal(0., 12., N)\n",
    "    y = 10*X + e #Note the use of broadcasting here\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "X, y = generate_dataset()\n",
    "# Now lets visualize our data\n",
    "plt.plot(X, y, 'bo')\n",
    "plt.show()\n",
    "\n",
    "# get N  ------> ? \n",
    "N = 0#fill in these\n",
    "\n",
    "# shuffle the dataset randomly\n",
    "# X, y contains the data after shuffling randomly X and y\n",
    "X, y = [], [] # ?\n",
    "\n",
    "# Created train and test set\n",
    "training_size = int(0.8*N)\n",
    "\n",
    "X_train = X[:training_size]\n",
    "y_train = y[:training_size]\n",
    "X_test = X[training_size:]\n",
    "y_test = y[training_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-5668cd4747ed>, line 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-5668cd4747ed>\"\u001b[0;36m, line \u001b[0;32m28\u001b[0m\n\u001b[0;31m    w_grad = # ? Compute derivate of loss wrt w\u001b[0m\n\u001b[0m                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class LinearRegression(object):\n",
    "    def __init__(self):\n",
    "        #Initialize all parameters\n",
    "        self.w = #? Sample from a uniform distribution between -1 and 1\n",
    "        self.b = #? Sample from a uniform distribution between -1 and 1\n",
    "    \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "            Do a forward pass of the classifier:\n",
    "            Args:\n",
    "                x: Input X value\n",
    "            Return:\n",
    "                y: y = wx + b\n",
    "        '''\n",
    "        # Complete this function\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    \n",
    "    def backward(self, x, ypred, y_train, lr):\n",
    "        '''\n",
    "            Computes all gradients and updates the parameters w and b\n",
    "            Args:\n",
    "                x : x\n",
    "                ypred: y=wx+b\n",
    "                y_train = ground truth values\n",
    "                lr = learning rate\n",
    "        '''\n",
    "        w_grad = # ? Compute derivate of loss wrt w \n",
    "        b_grad = # ? Compute derivate of loss wrt w\n",
    "        self.w = self.w - lr*w_grad # Updating w\n",
    "        self.b = self.b - lr*b_grad # Updating b\n",
    "\n",
    "def MSELoss(y, ypred):\n",
    "    '''\n",
    "        Args:\n",
    "            y: ground truth labels\n",
    "            ypred: predicted labels\n",
    "        Return:\n",
    "            Mean squared error loss\n",
    "    '''\n",
    "    # Complete this function\n",
    "    raise NotImplementedError\n",
    "        \n",
    "\n",
    "print 'Starting Training with Gradient Descent'\n",
    "lreg = LinearRegression()\n",
    "epochs = 10000\n",
    "learning_rate = 0.00001\n",
    "\n",
    "loss_history = []\n",
    "epoch_history = []\n",
    "\n",
    "# Gradient Descent\n",
    "for e in range(epochs):\n",
    "    ypred = lreg.forward(X_train)\n",
    "    loss = MSELoss(y_train, ypred)\n",
    "    if e==0 or (e+1)%1000==0:\n",
    "        loss_history.append(loss)\n",
    "        epoch_history.append(e+1)\n",
    "    \n",
    "    lreg.backward(X_train, ypred, y_train, learning_rate)\n",
    "\n",
    "print 'Loss fuction decrease after ' + str(epochs) + ' epochs of training'\n",
    "\n",
    "#Plot the decrease in loss with epoch\n",
    "plt.plot(epoch_history, loss_history)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-29da5f54db7b>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-29da5f54db7b>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    ypred =  # find predictions on test set ?\u001b[0m\n\u001b[0m                                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "print 'Final Training loss:' + str()  # Print training loss ?\n",
    "print 'Starting to test'\n",
    "ypred =  # find predictions on test set ?\n",
    "loss = # compute loss on test set ?\n",
    "print 'Final test loss: ' + str(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print 'Visualizing learnt function on test data'\n",
    "\n",
    "x_ = np.arange(100)\n",
    "y_ = lreg.w*x_ + lreg.b\n",
    "\n",
    "plt.plot(x_, y_, 'r-', linewidth=2.0)\n",
    "plt.plot(X_test, y_test, 'bo')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
